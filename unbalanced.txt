#METHODS
Tomek Links
https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets

# decision tree  on imbalanced dataset with SMOTE oversampling and random undersampling
from numpy import mean
from sklearn.datasets import make_classification
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.tree import DecisionTreeClassifier
from imblearn.pipeline import Pipeline
from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import RandomUnderSampler
# define pipeline
model = DecisionTreeClassifier(max_depth= 4, random_state = 53, min_samples_leaf= 300)
over = SMOTE(sampling_strategy=0.5)
under = RandomUnderSampler(sampling_strategy=0.5)
steps = [('over', over), ('under', under), ('model', model)]
pipeline = Pipeline(steps=steps)
# evaluate pipeline
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
scores = cross_val_score(pipeline, X_train, y_train, scoring='roc_auc', cv=cv)
print('Mean ROC AUC: %.3f' % mean(scores))


from imblearn.over_sampling import SMOTE
from imblearn.under_sampling import OneSidedSelection
#Fitting the model
overs = SMOTE(sampling_strategy=0.2, random_state= 0)
os_X_train,os_y_train = overs.fit_resample(X_train,y_train)
# define the undersampling method
undersample = OneSidedSelection(n_neighbors=4, n_seeds_S=800, random_state=6)
# transform the dataset
rs_Xtrain, rs_ytrain = undersample.fit_resample(os_X_train,os_y_train)
rnd_forest.fit(rs_Xtrain,rs_ytrain)